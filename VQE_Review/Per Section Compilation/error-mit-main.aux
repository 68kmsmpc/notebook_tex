\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\orcidauthor{0000-0001-5034-474X}{A B}
\citation{Bittel2021}
\citation{gentini_noise-resilient_2020,Wang2020}
\citation{Franca2021}
\citation{McClean2018}
\citation{nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021,Romero2019,schuld_evaluating_2019}
\citation{koczor_quantum_2020,parrish_jacobi_2019}
\citation{Arrasmith2020,Kubler2020adaptiveoptimizer}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Optimization strategies}{1}{section.1}\protected@file@percent }
\newlabel{sec:Optimization}{{1}{1}{Optimization strategies}{section.1}{}}
\citation{CostFunction2020Cao,nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021,koczor_quantum_2020,schuld_evaluating_2019,Romero2019}
\citation{ebel_dispersive_2021,lu_nmr_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Background and notation}{2}{subsection.1.1}\protected@file@percent }
\citation{kiefer_stochastic_1952}
\citation{kiefer_stochastic_1952}
\citation{s_performance_2012,morison_spsa_2003,wang_mixed_2018}
\citation{Spall1997AcceleratedMeasurements}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Gradient evaluation}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Stochastic approximation methods }{3}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{sec:stochastic_approximation}{{1.2.1}{3}{Stochastic approximation methods}{subsubsection.1.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Finite difference stochastic approximation (FDSA)}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simultaneous perturbation stochastic approximation (SPSA)}{3}{section*.3}\protected@file@percent }
\citation{mitarai_methodology_2019}
\citation{Romero2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Analytical gradient calculation}{4}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{eq:exactDerivative}{{18}{4}{Analytical gradient calculation}{equation.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Direct analytical gradient measurement}{4}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Indirect analytical gradient measurement}{4}{section*.6}\protected@file@percent }
\citation{schuld_evaluating_2019}
\citation{schuld_evaluating_2019,Hubregtsen2022}
\citation{crooks_gradients_2019}
\citation{izmaylov_analytic_2021}
\citation{izmaylov_analytic_2021}
\citation{GeneralGradientsWierichs2022,OptimalityCircuits2021Theis}
\citation{Kottmann2021_3}
\newlabel{eq:optimization:shift_rule_principal}{{26}{5}{Indirect analytical gradient measurement}{equation.26}{}}
\citation{Lemarechal12cauchyand,Courant1943Variational}
\citation{kingma_adam_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Gradient-based searching strategy}{6}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}First order optimizers}{6}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simple gradient descent}{6}{section*.7}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Simple gradient descent}}{6}{algocf.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RMSProp}{6}{section*.8}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces RMSProp optimizer}}{6}{algocf.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Adam optimizer}{6}{section*.9}\protected@file@percent }
\citation{broyden_convergence_1970,fletcher_new_1970,goldfarb_family_1970,shanno_conditioning_1970}
\citation{byrdt_limited_nodate}
\citation{huembeli_characterizing_2021}
\citation{amari_natural_1998,martens_new_2020,wierichs_avoiding_2020}
\citation{Wiersema2022OptimizingGradientFlow}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Adam optimizer}}{7}{algocf.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Second order optimizers}{7}{subsubsection.1.3.2}\protected@file@percent }
\newlabel{sec:second_order_optimizers}{{1.3.2}{7}{Second order optimizers}{subsubsection.1.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm}{7}{section*.10}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces BFGS algorithm}}{7}{algocf.4}\protected@file@percent }
\citation{stokes_quantum_2020}
\citation{McArdle2019}
\citation{Kullback1951}
\citation{safranek_simple_2018,liu_quantum_2020}
\citation{wierichs_avoiding_2020,yamamoto_natural_2019,stokes_quantum_2020,Straaten2020}
\citation{koczor_quantum_2020}
\@writefile{toc}{\contentsline {paragraph}{Quantum natural gradient}{8}{section*.11}\protected@file@percent }
\citation{haug_optimal_2021}
\citation{Gacon2021simultaneous}
\citation{Gacon2021simultaneous}
\citation{nelder_simplex_1965}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Gradient-free searching strategy}{9}{subsection.1.4}\protected@file@percent }
\citation{Lavrijsen2020ClassicalDevices,Pellow-Jarman2021}
\citation{Powell1964}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Gradient-free optimizers}{10}{subsubsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Nelder-Mead algorithm}{10}{section*.12}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Nelder-Mead algorithm}}{10}{algocf.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Powell's conjugate direction algorithm}{10}{section*.13}\protected@file@percent }
\citation{Vidal2018,nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Powell's algorithm}}{11}{algocf.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Analytical optimization}{11}{subsubsection.1.4.2}\protected@file@percent }
\newlabel{sec:analytical_opt}{{1.4.2}{11}{Analytical optimization}{subsubsection.1.4.2}{}}
\newlabel{fullansatz}{{49}{11}{Analytical optimization}{equation.49}{}}
\newlabel{eq:optimization:ansatz_expansion}{{51}{11}{Analytical optimization}{equation.51}{}}
\@writefile{toc}{\contentsline {paragraph}{Sequential optimization with sinusoidal fitting (Rotosolve)}{11}{section*.14}\protected@file@percent }
\citation{GeneralGradientsWierichs2022,Vidal2018CalculusQuantumCircuit}
\citation{Wierichs2022}
\citation{Watanabe2021WatanabeOptimizingSelection}
\citation{Wada2021SimulatingCircuits}
\@writefile{toc}{\contentsline {paragraph}{Analytical Free-Axis Selection with fixed rotation angles (Fraxis)}{12}{section*.15}\protected@file@percent }
\newlabel{eq:fraxis}{{62}{12}{Analytical Free-Axis Selection with fixed rotation angles (Fraxis)}{equation.62}{}}
\citation{sung_using_2020}
\citation{koczor_quantum_2020}
\newlabel{eq:R-def}{{69}{13}{Analytical Free-Axis Selection with fixed rotation angles (Fraxis)}{equation.69}{}}
\@writefile{toc}{\contentsline {paragraph}{Quantum analytical descent}{13}{section*.16}\protected@file@percent }
\newlabel{full-circuit}{{70}{13}{Quantum analytical descent}{equation.70}{}}
\newlabel{full-energy}{{71}{13}{Quantum analytical descent}{equation.71}{}}
\citation{parrish_jacobi_2019}
\citation{golub_eigenvalue_2000}
\citation{parrish_jacobi_2019}
\citation{zhang_collective_2020}
\@writefile{toc}{\contentsline {paragraph}{Jacobi diagonalization and Anderson acceleration}{14}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Engineering cost function}{14}{subsection.1.5}\protected@file@percent }
\newlabel{sec:cost_function}{{1.5}{14}{Engineering cost function}{subsection.1.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Collective optimization}{14}{section*.18}\protected@file@percent }
\citation{barkoutsos_improving_2020}
\citation{barkoutsos_improving_2020}
\citation{mccleanTheoryVariationalHybrid2015,Ryabinkin2019}
\citation{Ryabinkin2019}
\citation{Kandala2017}
\citation{mccleanTheoryVariationalHybrid2015,Ryabinkin2019}
\citation{KuroiwaPenaltyEigensolver2021}
\@writefile{toc}{\contentsline {paragraph}{Conditional Value-at-Risk as objective function}{15}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Symmetry preserving cost function adjustments:}{15}{section*.20}\protected@file@percent }
\citation{Pellow-Jarman2021,wierichs_avoiding_2020}
\citation{ExponentiallyNetworks2021}
\citation{kingma_adam_2017}
\citation{Lavrijsen2020ClassicalDevices,Pellow-Jarman2021,wierichs_avoiding_2020}
\citation{amari_natural_1998,martens_new_2020,wierichs_avoiding_2020}
\citation{Lavrijsen2020ClassicalDevices,Pellow-Jarman2021}
\citation{Pellow-Jarman2021}
\citation{nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021}
\citation{Watanabe2021WatanabeOptimizingSelection,Wada2021SimulatingCircuits}
\citation{koczor_quantum_2020}
\citation{golub_eigenvalue_2000}
\citation{zhang_collective_2020}
\citation{barkoutsos_improving_2020}
\citation{nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021,koczor_quantum_2020}
\citation{Mihlikov2022}
\citation{BonetMonroig2021}
\citation{BoydCoVar2022}
\citation{AcceleratingProcessesMueller2021,StochasticApplications2022Gidi,PattiMarkovChain2021}
\citation{haug_capacity_2021,haug_optimal_2021}
\citation{Vidal2018,nakanishi_sequential_2020,ostaszewskiStructureOptimizationParameterized2021,koczor_quantum_2020}
\citation{Okada2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Discussion}{16}{subsection.1.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of optimization strategies mentioned in this section. $C_M$ denotes the number of different measurement expectation values per iteration that need to be evaluated from the quantum computer. $C_C$ denotes the complexity of the classical algorithm for each iteration. Since the gradient can be evaluated or approximated with different methods, one can use $g^{(1)}$ to denote the cost of evaluating first order gradients and $g^{(2)}$ to denote the cost of evaluation second order gradients. $S$ denote the required sample shot number. $k$ denote the number of Hamiltonians with different bond distance being optimized simultaneously. $p$ denote the number of parameters in the ansatz.}}{17}{table.caption.21}\protected@file@percent }
\newlabel{table:optimizer_comparison}{{1}{17}{Comparison of optimization strategies mentioned in this section. $C_M$ denotes the number of different measurement expectation values per iteration that need to be evaluated from the quantum computer. $C_C$ denotes the complexity of the classical algorithm for each iteration. Since the gradient can be evaluated or approximated with different methods, one can use $g^{(1)}$ to denote the cost of evaluating first order gradients and $g^{(2)}$ to denote the cost of evaluation second order gradients. $S$ denote the required sample shot number. $k$ denote the number of Hamiltonians with different bond distance being optimized simultaneously. $p$ denote the number of parameters in the ansatz}{table.caption.21}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gradient_measurement}{{\caption@xref {fig:gradient_measurement}{ on input line 157}}{17}{Direct analytical gradient measurement}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Quantum circuit that evaluates $\operatorname  {Im} (\langle \phi _0| V^{j\dagger }_{k}(\boldsymbol  {\theta }) \hat  {M}_k U(\boldsymbol  {\theta })|\phi _0\rangle )$.}}{17}{figure.caption.5}\protected@file@percent }
\bibstyle{elsarticle-num}
\bibdata{../references}
\csxdef{lastpage}{19}
\gdef \@abspage@last{18}
